{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d47cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "#calculate the Eye Aspect Ratio (EAR)     \n",
    "def eye_aspect_ratio(eye_points, facial_landmarks):\n",
    "    # Compute the euclidean distances between the two sets of vertical eye landmarks\n",
    "    A = np.linalg.norm(facial_landmarks[eye_points[1]] - facial_landmarks[eye_points[5]])\n",
    "    B = np.linalg.norm(facial_landmarks[eye_points[2]] - facial_landmarks[eye_points[4]])\n",
    "\n",
    "    # Compute the euclidean distance between the two horizontal eye landmarks\n",
    "    C = np.linalg.norm(facial_landmarks[eye_points[0]] - facial_landmarks[eye_points[3]])\n",
    "\n",
    "    # Calculate the EAR\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "#-------------------------------------\n",
    "\n",
    "#landmarks for the left and right eyes\n",
    "RIGHT_EYE_INDICES = [33, 161, 160, 159, 158, 157, 173]\n",
    "LEFT_EYE_INDICES = [263, 249, 390, 373, 374, 380, 362]\n",
    "#-------------------------------------\n",
    "#threshold for EAR\n",
    "EAR_THRESHOLD = 0.2\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    blinked = False\n",
    "    start_time = None\n",
    "    blink_counter = 0\n",
    "\n",
    "    while webcam.isOpened():\n",
    "        success, img = webcam.read()\n",
    "\n",
    "        if not success:\n",
    "            print(\"Failed to capture frame from webcam. Ignoring process\")\n",
    "            break\n",
    "\n",
    "        # applying face mesh model using mediapipe\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(img)\n",
    "\n",
    "        # draw annotations on the image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                # Border around Face, eyes, lips\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
    "                )\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "                )\n",
    "\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style()\n",
    "                )\n",
    "                \n",
    "    \n",
    "                if results.multi_face_landmarks:\n",
    "                    for face_landmarks in results.multi_face_landmarks:\n",
    "\n",
    "                        # Extract landmarks\n",
    "                        landmarks = face_landmarks.landmark\n",
    "                        landmarks = np.array([(landmark.x, landmark.y, landmark.z) for landmark in landmarks])\n",
    "\n",
    "                        # Calculate the EAR for both eyes\n",
    "                        left_eye_ear = eye_aspect_ratio(LEFT_EYE_INDICES, landmarks)\n",
    "                        right_eye_ear = eye_aspect_ratio(RIGHT_EYE_INDICES, landmarks)\n",
    "                        average_ear = (left_eye_ear + right_eye_ear) / 2.0\n",
    "\n",
    "                        # Detect blinks and update the counter\n",
    "                        if average_ear < EAR_THRESHOLD:\n",
    "                            if not blinked:\n",
    "                                blinked = True\n",
    "                                blink_counter += 1\n",
    "                        else:\n",
    "                            blinked = False\n",
    "\n",
    "                        # Display blink counter on the frame\n",
    "                        cv2.putText(img, f'Blinking Eye: {blink_counter}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "            \n",
    "        # display frame\n",
    "        cv2.imshow('BCI keyboard', img)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf9d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facemesh with detection of blinking eye, works but needs improvement regarding \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "msg_display_time = None\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    refine_landmarks=True,\n",
    "    #min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    blinked = False\n",
    "    start_time = None\n",
    "\n",
    "    while webcam.isOpened():\n",
    "        success, img = webcam.read()\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Failed to capture frame from webcam. Ignoring process\")\n",
    "            break\n",
    "\n",
    "        # applying face mesh model using mediapipe\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(img)\n",
    "\n",
    "        # draw annotations on the image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                \n",
    "                #Border around Face, eyes, lips\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None, \n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
    "                )\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None, \n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "                )\n",
    "                \n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style()\n",
    "                )\n",
    "                \n",
    "                # calculate eye aspect ratio (EAR) to detect blink\n",
    "                RIGHT_EYE = [33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145]\n",
    "                right_eye = [face_landmarks.landmark[idx] for idx in RIGHT_EYE]\n",
    "                right_eye_h = np.linalg.norm(right_eye[1].x - right_eye[5].x)\n",
    "                right_eye_v1 = np.linalg.norm(right_eye[2].y - right_eye[4].y)\n",
    "                right_eye_v2 = np.linalg.norm(right_eye[0].y - right_eye[3].y)\n",
    "                EAR_right = (right_eye_v1 + right_eye_v2) / (2 * right_eye_h)\n",
    "                \n",
    "                if EAR_right < 0.1:\n",
    "                    if blinked is False:\n",
    "                        blinked = True\n",
    "                        start_time = time.time()\n",
    "                        cv2.putText(img, \"Blink Detected\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    \n",
    "                    else:\n",
    "                        if blinked is True:\n",
    "                            passed_time = time.time() - start_time\n",
    "                            if passed_time > 5:\n",
    "                                blinked = False\n",
    "                                start_time = None\n",
    "\n",
    "        cv2.imshow('Webcam', img)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500099cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular facemesh code without any detection process\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence =0.5) as face_mesh:\n",
    "    while webcam.isOpened():\n",
    "        success, img = webcam.read()\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Failed to capture frame from webcam. Ignoring process\")\n",
    "            break\n",
    "\n",
    "        # applying face mesh model using mediapipe\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(img)\n",
    "\n",
    "        # draw annotations on the image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                \n",
    "                #Border around Face, eyes, lips\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=None, #mp_drawing.DrawingSpec(color=(0,0,255)),\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
    "                )\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,#alternatively mp_drawing.DrawingSpec(color=(0,0,255)), \n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "                )\n",
    "                \n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image=img,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style()\n",
    "                )\n",
    "                \n",
    "        cv2.imshow('Webcam', img)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de7cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facemesh version with a square on the face and a few red dots representing landmarks of the face (eyes, ears,etc)\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection.FaceDetection(min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "while webcam.isOpened():\n",
    "    success, img = webcam.read()\n",
    "    # face detection using mediapipe\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = mp_face_detection.process(img)\n",
    "    \n",
    "    # draw the face detection annotations on the image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    if results.detections:#if there are faces in the image then draw rectangles on the face,etc\n",
    "        for detection in results.detections:\n",
    "            mp_drawing.draw_detection(img, detection)#we pass the image and the detection\n",
    "    \n",
    "    if success:\n",
    "        cv2.imshow(\"Webcam\", img)\n",
    "    else:\n",
    "        print(\"Error reading frame from webcam.\")\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "mp_face_detection.close()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
